{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from spacy import Language\n",
    "import spacy\n",
    "\n",
    "\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from typing import List, Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>type</th>\n",
       "      <th>E&gt;I</th>\n",
       "      <th>N&gt;S</th>\n",
       "      <th>F&gt;T</th>\n",
       "      <th>J&gt;P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[@Pericles216 @HierBeforeTheAC @Sachinettiyil ...</td>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@Hispanthicckk Being you makes you look cute,...</td>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[@Alshymi Les balles sont réelles et sont tiré...</td>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[I'm like entp but idiotic, Hey boy, do you wa...</td>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[@kaeshurr1 Give it to @ZargarShanif ... He ha...</td>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  type    E>I   N>S  \\\n",
       "user                                                                         \n",
       "0     [@Pericles216 @HierBeforeTheAC @Sachinettiyil ...  intj  False  True   \n",
       "1     [@Hispanthicckk Being you makes you look cute,...  intj  False  True   \n",
       "2     [@Alshymi Les balles sont réelles et sont tiré...  intj  False  True   \n",
       "3     [I'm like entp but idiotic, Hey boy, do you wa...  intj  False  True   \n",
       "4     [@kaeshurr1 Give it to @ZargarShanif ... He ha...  intj  False  True   \n",
       "\n",
       "        F>T   J>P  \n",
       "user               \n",
       "0     False  True  \n",
       "1     False  True  \n",
       "2     False  True  \n",
       "3     False  True  \n",
       "4     False  True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = pd.read_csv('data/twitter_MBTI.csv')\n",
    "\n",
    "# set proper column names\n",
    "twitter_df.columns = ['user', 'tweets', 'type']\n",
    "\n",
    "# set user as index\n",
    "twitter_df.set_index('user', inplace=True)\n",
    "\n",
    "# break up tweets single text into an array of tweets\n",
    "twitter_df['tweets'] = twitter_df['tweets'].apply(lambda x: x.split('|||'))\n",
    "\n",
    "# Extract user type dimensions (E/I, N/S, F/T, J/P) into separate columns\n",
    "twitter_df['E>I'] = twitter_df['type'].apply(lambda x: x[0]=='e')\n",
    "twitter_df['N>S'] = twitter_df['type'].apply(lambda x: x[1]=='n')\n",
    "twitter_df['F>T'] = twitter_df['type'].apply(lambda x: x[2]=='f')\n",
    "twitter_df['J>P'] = twitter_df['type'].apply(lambda x: x[3]=='j')\n",
    "\n",
    "twitter_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x25986753c50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: run first python -m spacy download en_core_web_sm\n",
    "\n",
    "# @Language.factory(\"language_detector\")\n",
    "# def get_lang_detector(nlp, name):\n",
    "#    return LanguageDetector()\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp.add_pipe('language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets before non-english drop: 1093199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# drop out non-english tweets\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumber of tweets before non-english drop: \u001b[39m\u001b[39m{\u001b[39;00muser_corpus_df[\u001b[39m\"\u001b[39m\u001b[39mtweets\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlen\u001b[39m)\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m user_corpus_df[\u001b[39m'\u001b[39m\u001b[39mtweets\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m user_corpus_df[\u001b[39m'\u001b[39;49m\u001b[39mtweets\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m      8\u001b[0m     \u001b[39mlambda\u001b[39;49;00m tweets: [\n\u001b[0;32m      9\u001b[0m         t \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m tweets \n\u001b[0;32m     10\u001b[0m         \u001b[39mif\u001b[39;49;00m nlp(t)\u001b[39m.\u001b[39;49m_\u001b[39m.\u001b[39;49mlanguage\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mlanguage\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     11\u001b[0m     ])\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumber of tweets after non-english drop: \u001b[39m\u001b[39m{\u001b[39;00muser_corpus_df[\u001b[39m\"\u001b[39m\u001b[39mtweets\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlen\u001b[39m)\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39m# merge all tweets into a single corpus\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Proprietario\\Desktop\\codici git\\ADS_mbti\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\Proprietario\\Desktop\\codici git\\ADS_mbti\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Proprietario\\Desktop\\codici git\\ADS_mbti\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Proprietario\\Desktop\\codici git\\ADS_mbti\\.venv\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(tweets)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# drop out non-english tweets\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumber of tweets before non-english drop: \u001b[39m\u001b[39m{\u001b[39;00muser_corpus_df[\u001b[39m\"\u001b[39m\u001b[39mtweets\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlen\u001b[39m)\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m user_corpus_df[\u001b[39m'\u001b[39m\u001b[39mtweets\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m user_corpus_df[\u001b[39m'\u001b[39m\u001b[39mtweets\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mlambda\u001b[39;00m tweets: [\n\u001b[0;32m      9\u001b[0m         t \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m tweets \n\u001b[0;32m     10\u001b[0m         \u001b[39mif\u001b[39;49;00m nlp(t)\u001b[39m.\u001b[39;49m_\u001b[39m.\u001b[39;49mlanguage\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mlanguage\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     11\u001b[0m     ])\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumber of tweets after non-english drop: \u001b[39m\u001b[39m{\u001b[39;00muser_corpus_df[\u001b[39m\"\u001b[39m\u001b[39mtweets\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlen\u001b[39m)\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39m# merge all tweets into a single corpus\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# drop out non-english tweets\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumber of tweets before non-english drop: \u001b[39m\u001b[39m{\u001b[39;00muser_corpus_df[\u001b[39m\"\u001b[39m\u001b[39mtweets\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlen\u001b[39m)\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m user_corpus_df[\u001b[39m'\u001b[39m\u001b[39mtweets\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m user_corpus_df[\u001b[39m'\u001b[39m\u001b[39mtweets\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\n\u001b[0;32m      8\u001b[0m     \u001b[39mlambda\u001b[39;00m tweets: [\n\u001b[0;32m      9\u001b[0m         t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tweets \n\u001b[1;32m---> 10\u001b[0m         \u001b[39mif\u001b[39;00m nlp(t)\u001b[39m.\u001b[39m_\u001b[39m.\u001b[39mlanguage\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39men\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     11\u001b[0m     ])\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumber of tweets after non-english drop: \u001b[39m\u001b[39m{\u001b[39;00muser_corpus_df[\u001b[39m\"\u001b[39m\u001b[39mtweets\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlen\u001b[39m)\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39m# merge all tweets into a single corpus\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Proprietario\\Desktop\\codici git\\ADS_mbti\\.venv\\Lib\\site-packages\\spacy\\language.py:1010\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[39mif\u001b[39;00m component_cfg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1009\u001b[0m     component_cfg \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1010\u001b[0m \u001b[39mfor\u001b[39;00m name, proc \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline:\n\u001b[0;32m   1011\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m disable:\n\u001b[0;32m   1012\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Proprietario\\Desktop\\codici git\\ADS_mbti\\.venv\\Lib\\site-packages\\spacy\\language.py:323\u001b[0m, in \u001b[0;36mLanguage.pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    320\u001b[0m     names \u001b[39m=\u001b[39m [pipe_name \u001b[39mfor\u001b[39;00m pipe_name, _ \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_components]\n\u001b[0;32m    321\u001b[0m     \u001b[39mreturn\u001b[39;00m SimpleFrozenList(names, error\u001b[39m=\u001b[39mErrors\u001b[39m.\u001b[39mE926\u001b[39m.\u001b[39mformat(attr\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcomponent_names\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m--> 323\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpipeline\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[\u001b[39mstr\u001b[39m, PipeCallable]]:\n\u001b[0;32m    325\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"The processing pipeline consisting of (name, component) tuples. The\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[39m    components are called on the Doc in order as it passes through the\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39m    pipeline.\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \n\u001b[0;32m    329\u001b[0m \u001b[39m    RETURNS (List[Tuple[str, Callable[[Doc], Doc]]]): The pipeline.\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    331\u001b[0m     pipes \u001b[39m=\u001b[39m [(n, p) \u001b[39mfor\u001b[39;00m n, p \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_components \u001b[39mif\u001b[39;00m n \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_disabled]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create a dataset with just user corpus\n",
    "\n",
    "user_corpus_df = twitter_df.copy()\n",
    "\n",
    "# # drop out non-english tweets\n",
    "# print(f'Number of tweets before non-english drop: {user_corpus_df[\"tweets\"].apply(len).sum()}')\n",
    "# user_corpus_df['tweets'] = user_corpus_df['tweets'].apply(\n",
    "#     lambda tweets: [\n",
    "#         t for t in tweets \n",
    "#         if nlp(t)._.language.get('language') == 'en'\n",
    "#     ])\n",
    "\n",
    "# print(f'Number of tweets after non-english drop: {user_corpus_df[\"tweets\"].apply(len).sum()}')\n",
    "\n",
    "# merge all tweets into a single corpus\n",
    "user_corpus_df['n_tweets'] = user_corpus_df['tweets'].apply(lambda x: len(x))\n",
    "user_corpus_df['avg_tweets_len'] = user_corpus_df['tweets'].apply(lambda x: sum([len(tweet) for tweet in x])/len(x))\n",
    "user_corpus_df['corpus'] = user_corpus_df['tweets'].apply(lambda x: ' '.join(x))\n",
    "user_corpus_df.drop(columns=['tweets',], inplace=True)\n",
    "\n",
    "user_corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(\n",
    "        text, tokenizer, lemmatizer, n=1, \n",
    "        remove_stopwords=False, remove_punctuation=False, \n",
    "        keep_sequence_and_dups=False): \n",
    "\n",
    "    # to lower case and tokenization\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "\n",
    "    # we don't always want to remove stopword and punctuation...\n",
    "    if remove_stopwords:\n",
    "        tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    \n",
    "    if remove_punctuation:\n",
    "        tokens = [token for token in tokens if token.isalpha()]\n",
    "\n",
    "\n",
    "    # lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # ngram generation \n",
    "    if keep_sequence_and_dups:\n",
    "        ngrams_out = []\n",
    "    else:\n",
    "        ngrams_out = set()\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        new_grams = [' '.join(grams) for grams in ngrams(tokens, i)]\n",
    "        if keep_sequence_and_dups:\n",
    "            ngrams_out.extend(new_grams)\n",
    "        else:\n",
    "            ngrams_out.update(new_grams)\n",
    "\n",
    "    return ngrams_out\n",
    "\n",
    "def preprocess_array(x, tokenizer, lemmatizer, n=1, \n",
    "        remove_stopwords=False, remove_punctuation=False, \n",
    "        keep_sequence_and_dups=False):\n",
    "    return [preprocess(\n",
    "        text, tokenizer, lemmatizer, \n",
    "        n, remove_stopwords, remove_punctuation, \n",
    "        keep_sequence_and_dups) for text in x\n",
    "        ]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>E</th>\n",
       "      <th>I</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "      <th>J</th>\n",
       "      <th>P</th>\n",
       "      <th>n_tweets</th>\n",
       "      <th>avg_tweets_len</th>\n",
       "      <th>corpus</th>\n",
       "      <th>proc_corpus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>179</td>\n",
       "      <td>104.865922</td>\n",
       "      <td>@Pericles216 @HierBeforeTheAC @Sachinettiyil T...</td>\n",
       "      <td>[the, pope, is, infallible, ,, this, is, a, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>113</td>\n",
       "      <td>64.362832</td>\n",
       "      <td>@Hispanthicckk Being you makes you look cute @...</td>\n",
       "      <td>[being, you, make, you, look, cute, on, ,, bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>115</td>\n",
       "      <td>89.156522</td>\n",
       "      <td>@Alshymi Les balles sont réelles et sont tirée...</td>\n",
       "      <td>[le, balles, sont, réelles, et, sont, tirées, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>201</td>\n",
       "      <td>27.253731</td>\n",
       "      <td>I'm like entp but idiotic Hey boy, do you want...</td>\n",
       "      <td>[i'm, like, entp, but, idiotic, hey, boy, ,, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>199</td>\n",
       "      <td>42.874372</td>\n",
       "      <td>@kaeshurr1 Give it to @ZargarShanif ... He has...</td>\n",
       "      <td>[give, it, to, ..., he, ha, pica, since, child...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type      E     I     N      S      F     T     J      P  n_tweets  \\\n",
       "user                                                                       \n",
       "0     intj  False  True  True  False  False  True  True  False       179   \n",
       "1     intj  False  True  True  False  False  True  True  False       113   \n",
       "2     intj  False  True  True  False  False  True  True  False       115   \n",
       "3     intj  False  True  True  False  False  True  True  False       201   \n",
       "4     intj  False  True  True  False  False  True  True  False       199   \n",
       "\n",
       "      avg_tweets_len                                             corpus  \\\n",
       "user                                                                      \n",
       "0         104.865922  @Pericles216 @HierBeforeTheAC @Sachinettiyil T...   \n",
       "1          64.362832  @Hispanthicckk Being you makes you look cute @...   \n",
       "2          89.156522  @Alshymi Les balles sont réelles et sont tirée...   \n",
       "3          27.253731  I'm like entp but idiotic Hey boy, do you want...   \n",
       "4          42.874372  @kaeshurr1 Give it to @ZargarShanif ... He has...   \n",
       "\n",
       "                                            proc_corpus  \n",
       "user                                                     \n",
       "0     [the, pope, is, infallible, ,, this, is, a, ca...  \n",
       "1     [being, you, make, you, look, cute, on, ,, bec...  \n",
       "2     [le, balles, sont, réelles, et, sont, tirées, ...  \n",
       "3     [i'm, like, entp, but, idiotic, hey, boy, ,, d...  \n",
       "4     [give, it, to, ..., he, ha, pica, since, child...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess corpus\n",
    "user_corpus_df['proc_corpus'] = user_corpus_df['corpus'].apply(\n",
    "    lambda x: preprocess(\n",
    "        x, tokenizer, lemmatizer, n=1, \n",
    "        keep_sequence_and_dups=True))\n",
    "\n",
    "user_corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take also a simpler version ignoring sequence and duplicates\n",
    "user_corpus_df['proc_corpus2'] = user_corpus_df['corpus'].apply(\n",
    "    lambda x: set(x)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:\t 7344\n",
      "Number of documents:\t 7811\n"
     ]
    }
   ],
   "source": [
    "def build_dictionary(corpus_list: list): \n",
    "\n",
    "    dictionary = defaultdict(set)\n",
    "\n",
    "    for i,c in enumerate(corpus_list):\n",
    "        for token in c:\n",
    "            dictionary[token].add(i)\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "dictionary = build_dictionary(user_corpus_df['proc_corpus2'])\n",
    "print(\"Number of tokens:\\t\", len(dictionary.keys()))\n",
    "print(\"Number of documents:\\t\", len(user_corpus_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6408431572849023"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_entropy(df: pd.DataFrame, class_label: str) -> float: \n",
    "    \"\"\"Calculate entropy of a column in a dataframe\"\"\"\n",
    "\n",
    "    # extimate probability of each class label\n",
    "    p = df[class_label].value_counts(normalize=True)\n",
    "\n",
    "    return -sum([p_i * np.log2(p_i) for p_i in p])\n",
    "\n",
    "H = df_entropy(user_corpus_df, 'type')\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terms_information_gain(df: pd.DataFrame, dictionary: dict): \n",
    "\n",
    "    ig = dict()\n",
    "\n",
    "    for term in dictionary.keys():\n",
    "        \n",
    "        # extract users who used that term \n",
    "        users = list(dictionary[term])\n",
    "\n",
    "        # create a dataframe with just those users and one with the rest\n",
    "        df_term = df.iloc[users]\n",
    "        df_rest = df.drop(index=df_term.index)\n",
    "\n",
    "        # calculate entropy of each group\n",
    "        ig[term] = H - len(df_term)/len(df) * df_entropy(df_term, 'type') \\\n",
    "            - len(df_rest)/len(df) * df_entropy(df_rest, 'type')\n",
    "        \n",
    "    return ig\n",
    "\n",
    "terms_ig = terms_information_gain(user_corpus_df, dictionary)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('😂', 0.0116509812957859)\n",
      "('🫶', 0.010801485264146482)\n",
      "('😭', 0.009700562049179684)\n",
      "('👏', 0.00784042725313272)\n",
      "('🥺', 0.007725078810263408)\n",
      "('🤍', 0.007499834739230327)\n",
      "('✨', 0.006986911508883864)\n",
      "('🥰', 0.006986395263362866)\n",
      "('🤣', 0.006372115636904763)\n",
      "('️', 0.006345499479745831) \n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select best 500 terms\n",
    "best_terms_ig = sorted(terms_ig.items(), key=lambda x: x[1], reverse=True)[:500]\n",
    "print('\\n'.join([str(t) for t in best_terms_ig[:10]]), '\\n...\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>E</th>\n",
       "      <th>I</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "      <th>J</th>\n",
       "      <th>P</th>\n",
       "      <th>n_tweets</th>\n",
       "      <th>avg_tweets_len</th>\n",
       "      <th>corpus</th>\n",
       "      <th>proc_corpus</th>\n",
       "      <th>proc_corpus2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>179</td>\n",
       "      <td>104.865922</td>\n",
       "      <td>@Pericles216 @HierBeforeTheAC @Sachinettiyil T...</td>\n",
       "      <td>[,, ’, …, …, …, ’, “, …, ’, ’, …, ’, ’, …, ’, ...</td>\n",
       "      <td>[!, _, ”, 6, …, 👆, (, “, \\n, 😎, -, \", @, 😳, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>113</td>\n",
       "      <td>64.362832</td>\n",
       "      <td>@Hispanthicckk Being you makes you look cute @...</td>\n",
       "      <td>[,, \", \", ,, ’, 😉, (, ,, ,, ,, ,, ,, …, …, …, ...</td>\n",
       "      <td>[!, _, 😘, 😂, ”, 6, 😉, …, (, “, \\n, 😎, -, \", @,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>115</td>\n",
       "      <td>89.156522</td>\n",
       "      <td>@Alshymi Les balles sont réelles et sont tirée...</td>\n",
       "      <td>[…, …, \", …, ,, ,, …, ️, (, …, \", \", !, %, ,, ...</td>\n",
       "      <td>[!, _, ✌, 6, …, ‍, 🤏, 😭, (, “, \\n, ️, -, \", @,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>201</td>\n",
       "      <td>27.253731</td>\n",
       "      <td>I'm like entp but idiotic Hey boy, do you want...</td>\n",
       "      <td>[,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,]</td>\n",
       "      <td>[,, ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>199</td>\n",
       "      <td>42.874372</td>\n",
       "      <td>@kaeshurr1 Give it to @ZargarShanif ... He has...</td>\n",
       "      <td>[❤, ️, 🥺, ,, 🥺, ,, %, …, 🥺, ❤, ️, 🥺, 🥺, 🥺, ,, ...</td>\n",
       "      <td>[🥹, _, 😂, 6, 🤧, …, ❤, 🥺, (, 🤣, \\n, ️, -, @, 🥲,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type      E     I     N      S      F     T     J      P  n_tweets  \\\n",
       "user                                                                       \n",
       "0     intj  False  True  True  False  False  True  True  False       179   \n",
       "1     intj  False  True  True  False  False  True  True  False       113   \n",
       "2     intj  False  True  True  False  False  True  True  False       115   \n",
       "3     intj  False  True  True  False  False  True  True  False       201   \n",
       "4     intj  False  True  True  False  False  True  True  False       199   \n",
       "\n",
       "      avg_tweets_len                                             corpus  \\\n",
       "user                                                                      \n",
       "0         104.865922  @Pericles216 @HierBeforeTheAC @Sachinettiyil T...   \n",
       "1          64.362832  @Hispanthicckk Being you makes you look cute @...   \n",
       "2          89.156522  @Alshymi Les balles sont réelles et sont tirée...   \n",
       "3          27.253731  I'm like entp but idiotic Hey boy, do you want...   \n",
       "4          42.874372  @kaeshurr1 Give it to @ZargarShanif ... He has...   \n",
       "\n",
       "                                            proc_corpus  \\\n",
       "user                                                      \n",
       "0     [,, ’, …, …, …, ’, “, …, ’, ’, …, ’, ’, …, ’, ...   \n",
       "1     [,, \", \", ,, ’, 😉, (, ,, ,, ,, ,, ,, …, …, …, ...   \n",
       "2     […, …, \", …, ,, ,, …, ️, (, …, \", \", !, %, ,, ...   \n",
       "3      [,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,]   \n",
       "4     [❤, ️, 🥺, ,, 🥺, ,, %, …, 🥺, ❤, ️, 🥺, 🥺, 🥺, ,, ...   \n",
       "\n",
       "                                           proc_corpus2  \n",
       "user                                                     \n",
       "0     [!, _, ”, 6, …, 👆, (, “, \\n, 😎, -, \", @, 😳, ,,...  \n",
       "1     [!, _, 😘, 😂, ”, 6, 😉, …, (, “, \\n, 😎, -, \", @,...  \n",
       "2     [!, _, ✌, 6, …, ‍, 🤏, 😭, (, “, \\n, ️, -, \", @,...  \n",
       "3                                                [,, ']  \n",
       "4     [🥹, _, 😂, 6, 🤧, …, ❤, 🥺, (, 🤣, \\n, ️, -, @, 🥲,...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only the best terms in the corpus\n",
    "\n",
    "user_corpus_df2 = user_corpus_df.copy()\n",
    "\n",
    "best_terms = [t[0] for t in best_terms_ig]\n",
    "\n",
    "user_corpus_df2['proc_corpus'] = user_corpus_df2['proc_corpus'].apply(\n",
    "    lambda x : [t for t in x if t in best_terms])\n",
    "user_corpus_df2['proc_corpus2'] = user_corpus_df2['proc_corpus2'].apply(\n",
    "    lambda x : [t for t in x if t in best_terms])\n",
    "\n",
    "user_corpus_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bow_to_numeric(bow: List[Set[str]], all_words: List[str]) -> np.ndarray:\n",
    "    \"\"\"Turn a list of BOW to a numeric matrix\"\"\"\n",
    "\n",
    "    features_indexes = {w:i for i,w in enumerate(all_words)}\n",
    "\n",
    "    data = np.zeros((len(bow), len(all_words)))\n",
    "\n",
    "    for i, doc in enumerate(bow):\n",
    "        for word in doc: \n",
    "            data[i, features_indexes[word]] = 1\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7811, 502)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert bow to numeric\n",
    "data = bow_to_numeric(user_corpus_df2['proc_corpus2'], best_terms)\n",
    "\n",
    "# add n tweets and avg tweets len\n",
    "data = np.hstack((data, user_corpus_df2[['n_tweets', 'avg_tweets_len']].values))\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7811,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set target (the personality type)\n",
    "\n",
    "mapping = { t:i for i,t in enumerate(user_corpus_df2['type'].unique()) }\n",
    "\n",
    "target = np.array([mapping[t] for t in user_corpus_df2['type']])\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selection criteria\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# models to apply \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Mean accuracy:\t 0.16898428468977078\n",
      "Std dev :\t 0.0739970209418566\n",
      "\n",
      "\n",
      "MultinomialNB\n",
      "Mean accuracy:\t 0.15491140285095834\n",
      "Std dev :\t 0.006929099162506796\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "Mean accuracy:\t 0.23428043265405032\n",
      "Std dev :\t 0.07169946437111722\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    DecisionTreeClassifier(),\n",
    "    MultinomialNB(),\n",
    "    RandomForestClassifier(),\n",
    "    # LogisticRegression()\n",
    "    ]\n",
    "\n",
    "# cross validation\n",
    "\n",
    "for model in models:\n",
    "    scores = cross_val_score(model, data, target, cv=10)\n",
    "    print(model.__class__.__name__)\n",
    "    print('Mean accuracy:\\t', scores.mean()) \n",
    "    print('Std dev :\\t', scores.std()) \n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try predict the single features\n",
    "\n",
    "scores_f = []\n",
    "\n",
    "for f in ['E>I', 'N>S', 'F>T', 'J>P', ]:\n",
    "\n",
    "    t = user_corpus_df2[f].values.astype(float)\n",
    "\n",
    "    for model in models:\n",
    "        scores_f.append(\n",
    "            (f, model.__class__.__name__,\n",
    "            cross_val_score(model, data, t, cv=10))\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\tDecisionTreeClassifier\t0.59\n",
      "E\tMultinomialNB\t0.62\n",
      "E\tRandomForestClassifier\t0.68\n",
      "I\tDecisionTreeClassifier\t0.58\n",
      "I\tMultinomialNB\t0.62\n",
      "I\tRandomForestClassifier\t0.68\n",
      "N\tDecisionTreeClassifier\t0.68\n",
      "N\tMultinomialNB\t0.69\n",
      "N\tRandomForestClassifier\t0.79\n",
      "S\tDecisionTreeClassifier\t0.67\n",
      "S\tMultinomialNB\t0.69\n",
      "S\tRandomForestClassifier\t0.78\n",
      "T\tDecisionTreeClassifier\t0.55\n",
      "T\tMultinomialNB\t0.56\n",
      "T\tRandomForestClassifier\t0.62\n",
      "F\tDecisionTreeClassifier\t0.55\n",
      "F\tMultinomialNB\t0.56\n",
      "F\tRandomForestClassifier\t0.62\n",
      "J\tDecisionTreeClassifier\t0.56\n",
      "J\tMultinomialNB\t0.57\n",
      "J\tRandomForestClassifier\t0.61\n",
      "P\tDecisionTreeClassifier\t0.56\n",
      "P\tMultinomialNB\t0.57\n",
      "P\tRandomForestClassifier\t0.61\n"
     ]
    }
   ],
   "source": [
    "for f, model, scores in scores_f:\n",
    "    print(f, model, round(scores.mean(), 2), sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
